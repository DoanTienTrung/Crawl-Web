from scrapers.base import NewsScraperBase
from typing import List, Tuple, Optional
from bs4 import BeautifulSoup
from datetime import datetime
import feedparser
import re


class DanTriRSSScraper(NewsScraperBase):
    """
    Scraper cho DanTri.com.vn sá»­ dá»¥ng RSS Feed
    """

    def __init__(self):
        super().__init__()
        self.source = "dantri.com.vn"
        self.rss_url = "https://dantri.com.vn/rss/tin-moi-nhat.rss"

    def fetch_news(self) -> List[Tuple]:
        """
        Láº¥y tá»‘i Ä‘a 20 tin tá»©c má»›i nháº¥t tá»« RSS feed cá»§a DÃ¢n trÃ­
        """
        all_articles = []
        print(f"\nğŸ“¡ Äang Ä‘á»c RSS tá»«: {self.rss_url} - multi_source_scraper.py:1084")

        # 1. Sá»­ dá»¥ng feedparser Ä‘á»ƒ Ä‘á»c ná»™i dung RSS
        feed = feedparser.parse(self.rss_url)

        if not feed.entries:
            print("âš  KhÃ´ng tÃ¬m tháº¥y bÃ i viáº¿t nÃ o trong RSS. - multi_source_scraper.py:1090")
            return []

        # 2. Giá»›i háº¡n chá»‰ xá»­ lÃ½ 20 bÃ i viáº¿t Ä‘áº§u tiÃªn
        entries_to_process = feed.entries[:20]
        print(f"TÃ¬m tháº¥y {len(feed.entries)} bÃ i. Sáº½ xá»­ lÃ½ {len(entries_to_process)} bÃ i má»›i nháº¥t. - multi_source_scraper.py:1095")

        for entry in entries_to_process:
            link = entry.link

            # Láº¥y Category trá»±c tiáº¿p tá»« tháº» <category> cá»§a RSS Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c (vÃ­ dá»¥: ChÃ­nh trá»‹)
            rss_category = getattr(entry, 'category', 'TIN Má»šI')

            print(f"Fetching: {link[:60]}... - multi_source_scraper.py:1103")
            self.sleep()

            # Truyá»n rss_category vÃ o hÃ m detail Ä‘á»ƒ xá»­ lÃ½
            article_data = self._fetch_article_detail(link, rss_category)
            if article_data:
                all_articles.append(article_data)

        print(f"\nâœ“ Tá»•ng sá»‘ bÃ i viáº¿t thu tháº­p Ä‘Æ°á»£c: {len(all_articles)} - multi_source_scraper.py:1111")
        return all_articles

    def _fetch_article_detail(self, link: str, rss_category: str = None) -> Optional[Tuple]:
        """Fetch chi tiáº¿t má»™t bÃ i bÃ¡o tá»« DÃ¢n trÃ­"""
        html = self.fetch_html(link)
        if not html:
            return None

        soup = BeautifulSoup(html, 'html.parser')

        # 1. TrÃ­ch xuáº¥t TiÃªu Ä‘á»
        title_el = soup.select_one('h1.title-page') or soup.select_one('h1')
        title = title_el.get_text(strip=True) if title_el else ''

        if not title:
            return None

        # 2. TrÃ­ch xuáº¥t NgÃ y xuáº¥t báº£n
        published_at = 0
        date_el = soup.select_one('.author-time')
        if date_el:
            date_text = date_el.get_text(strip=True)
            date_match = re.search(r'(\d{1,2})/(\d{1,2})/(\d{4})\s*-\s*(\d{1,2}):(\d{2})', date_text)
            if date_match:
                day, month, year, hour, minute = date_match.groups()
                try:
                    dt = datetime(int(year), int(month), int(day), int(hour), int(minute))
                    published_at = int(dt.timestamp())
                except:
                    pass

        # 3. TrÃ­ch xuáº¥t Ná»™i dung
        content = ""
        content_el = soup.select_one('.singular-content')
        if content_el:
            # Loáº¡i bá» quáº£ng cÃ¡o vÃ  video liÃªn quan
            for unwanted in content_el.select('.gui-check-parent, .video-content-wrapper, .ad-container'):
                unwanted.decompose()

            paragraphs = content_el.select('p')
            content = ' '.join([p.get_text(strip=True) for p in paragraphs if p.get_text(strip=True)])

        # 4. TrÃ­ch xuáº¥t ChuyÃªn má»¥c (Æ¯u tiÃªn tá»« RSS)
        if rss_category and rss_category != "TIN Má»šI":
            category = rss_category
        else:
            # Dá»± phÃ²ng láº¥y tá»« Meta Tag náº¿u RSS thiáº¿u
            meta_cate = soup.find('meta', property='article:section')
            category = meta_cate.get('content') if meta_cate else "TIN Má»šI"

        category = category.upper().strip()

        return (
            published_at,
            title,
            link,
            content,
            self.source,
            "NA",   
            "NA",  
            False,  
            category,
        )
