# Multi-Source News Scraper

Tool crawl tin tá»©c tá»« nhiá»u nguá»“n bÃ¡o Viá»‡t Nam vÃ  lÆ°u vÃ o PostgreSQL.

## Supported Sources

| Source | URL | Status |
|--------|-----|--------|
| CafeF | cafef.vn | âœ… |
| VnExpress | vnexpress.net | âœ… |
| VnEconomy | vneconomy.vn | âœ… |
| VOV | vov.vn | âœ… |
| Vietnamnet | vietnamnet.vn | âœ… |

## Database Schema

```sql
CREATE TABLE IF NOT EXISTS public.news (
    id uuid NOT NULL DEFAULT gen_random_uuid(),
    published_at bigint,
    title text NOT NULL,
    link text,
    content text,
    source text,
    stock_related text,
    sentiment_score text,
    server_pushed boolean DEFAULT false,
    created_at timestamp with time zone DEFAULT now(),
    category text,
    CONSTRAINT news_pkey PRIMARY KEY (id),
    CONSTRAINT news_title_key UNIQUE (title)
);
```

## CÃ i Ä‘áº·t

### 1. Clone vÃ  setup

```bash
cd news-scraper
python -m venv venv
venv\Scripts\activate  # Windows
pip install -r requirements.txt
```

### 2. Táº¡o database PostgreSQL

```sql
CREATE DATABASE news_db;
```

### 3. Cáº¥u hÃ¬nh .env

```bash
copy .env.example .env
```

Sá»­a file `.env`:
```
DB_HOST=localhost
DB_PORT=5432
DB_NAME=news_db
DB_USER=postgres
DB_PASSWORD=your_password
```

## Sá»­ dá»¥ng

### Scrape táº¥t cáº£ sources

```bash
python main.py
```

### Scrape tá»«ng source riÃªng

```bash
python main.py cafef        # Chá»‰ CafeF
python main.py vnexpress    # Chá»‰ VnExpress
python main.py vneconomy    # Chá»‰ VnEconomy status: processing
python main.py vov          # Chá»‰ VOV       status: processing
python main.py vietnamnet   # Chá»‰ Vietnamnet
```

### Export CSV only (khÃ´ng cáº§n database)

```bash
python main.py csv
```

### Test mode

```bash
python main.py test
```

## Output

### Database
- Table: `news`
- Primary key: `id` (UUID)
- Unique constraint: `title`

### CSV Files
- Location: `exports/`
- Format: `{source}_{timestamp}.csv`

### CSV Columns

| Column | Type | Description |
|--------|------|-------------|
| published_at | bigint | Unix timestamp |
| title | text | TiÃªu Ä‘á» bÃ i bÃ¡o |
| link | text | URL bÃ i bÃ¡o |
| content | text | Ná»™i dung |
| source | text | Nguá»“n (cafef.vn, vnexpress.net, ...) |
| stock_related | text | MÃ£ chá»©ng khoÃ¡n liÃªn quan |
| sentiment_score | text | Äiá»ƒm sentiment |
| server_pushed | boolean | ÄÃ£ push lÃªn server chÆ°a |
| category | text | ChuyÃªn má»¥c |

## Cáº¥u trÃºc Project

```
news-scraper/
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ config.py               # Configuration
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â”œâ”€â”€ README.md
â”‚
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ models.py           # SQLAlchemy models (News table)
â”‚
â”œâ”€â”€ scrapers/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_scraper.py     # Base class (Selenium-based)
â”‚   â”œâ”€â”€ cafef_scraper.py    # CafeF scraper (Selenium)
â”‚   â”œâ”€â”€ vnexpress_scraper.py
â”‚   â””â”€â”€ multi_source_scraper.py  # â­ All scrapers (requests-based)
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ exporters.py        # CSV & JSON exporters
â”‚
â””â”€â”€ exports/                # Output files
```

## So sÃ¡nh vá»›i code Rust gá»‘c

| Feature | Rust | Python |
|---------|------|--------|
| HTTP Client | reqwest | requests |
| HTML Parsing | scraper | BeautifulSoup |
| Database | sqlx (async) | SQLAlchemy |
| Compression | flate2, brotli | gzip, brotli |
| Browser automation | thirtyfour | selenium (optional) |

## ğŸ¤– Scheduler - Tá»± Ä‘á»™ng láº­p lá»‹ch scraping

### CÃ¡ch sá»­ dá»¥ng Scheduler

Scheduler giÃºp tá»± Ä‘á»™ng cháº¡y cÃ¡c scraper functions theo lá»‹ch Ä‘Ã£ Ä‘á»‹nh sáºµn.

#### 1. CÃ i Ä‘áº·t thÃªm APScheduler

```bash
pip install -r requirements.txt
```

#### 2. Cáº¥u hÃ¬nh lá»‹ch cháº¡y

Chá»‰nh sá»­a file `scheduler_config.json`:

```json
{
  "jobs": [
    {
      "id": "scrape_all_news_hourly",
      "name": "Scrape táº¥t cáº£ nguá»“n tin má»—i giá»",
      "function": "scrape_all",
      "enabled": true,
      "schedule": {
        "type": "interval",
        "hours": 1
      },
      "description": "Cháº¡y scrape_all() má»—i 1 giá»"
    }
  ],
  "timezone": "Asia/Ho_Chi_Minh",
  "log_file": "logs/news_scheduler.log",
  "log_level": "INFO"
}
```

#### 3. Cháº¡y Scheduler

```bash
python scheduler.py
```

Output:
```
[2026-01-02 10:00:00] INFO - ğŸš€ Scheduler started successfully!
[2026-01-02 10:00:00] INFO - â° Timezone: Asia/Ho_Chi_Minh
[2026-01-02 10:00:00] INFO - ğŸ“‹ Total active jobs: 1
[2026-01-02 10:00:00] INFO -   ğŸ• Scrape táº¥t cáº£ nguá»“n tin má»—i giá»
[2026-01-02 10:00:00] INFO -      Next run: 2026-01-02 11:00:00
```

#### 4. Dá»«ng Scheduler

Nháº¥n `Ctrl+C` Ä‘á»ƒ dá»«ng gracefully.

### CÃ¡c loáº¡i Schedule

#### Interval Schedule (cháº¡y má»—i X thá»i gian)

```json
{
  "type": "interval",
  "minutes": 30    // Má»—i 30 phÃºt
}

{
  "type": "interval",
  "hours": 2      // Má»—i 2 giá»
}
```

#### Cron Schedule (cháº¡y theo lá»‹ch cá»¥ thá»ƒ)

```json
{
  "type": "cron",
  "hour": "8",
  "minute": "0",
  "day_of_week": "mon-fri"    // 8:00 sÃ¡ng, thá»© 2-6
}

{
  "type": "cron",
  "minute": "*/15"    // Má»—i 15 phÃºt
}
```

### CÃ¡c Scraper Functions cÃ³ sáºµn

- `scrape_all` - Scrape táº¥t cáº£ nguá»“n
- `scrape_cafef` - CafeF
- `scrape_vnexpress` - VnExpress
- `scrape_vneconomy` - VnEconomy
- `scrape_vov` - VOV
- `scrape_vietnamnet` - Vietnamnet
- `scrape_dantri` - DÃ¢n trÃ­
- `scrape_thanhnien` - Thanh NiÃªn
- `scrape_tuoitre` - Tuá»•i Tráº»
- `scrape_laodong` - Lao Äá»™ng
- `scrape_nld` - NgÆ°á»i Lao Äá»™ng
- `scrape_vietstock` - VietStock
- `scrape_antt` - An ninh Thá»§ Ä‘Ã´
- `scrape_cna` - Channel NewsAsia
- `scrape_qdnd` - QuÃ¢n Ä‘á»™i NhÃ¢n dÃ¢n
- `scrape_kinhte` - Kinh táº¿ Ngoáº¡i thÆ°Æ¡ng
- `scrape_thoibaonganhang` - Thá»i bÃ¡o NgÃ¢n hÃ ng
- `scrape_taichinhdoanhnghiep` - TÃ i chÃ­nh Doanh nghiá»‡p
- `scrape_baochinhphu` - BÃ¡o ChÃ­nh phá»§

### Logs

Xem logs táº¡i: `logs/news_scheduler.log`

```bash
tail -f logs/news_scheduler.log    # Xem logs real-time
```

### Báº­t/Táº¯t Jobs

Äáº·t `"enabled": false` trong config Ä‘á»ƒ táº¯t job:

```json
{
  "id": "my_job",
  "enabled": false,
  ...
}
```

## LÆ°u Ã½

1. **Rate limiting**: Tool cÃ³ delay 2-3 giÃ¢y giá»¯a cÃ¡c request
2. **Duplicate handling**: DÃ¹ng UNIQUE constraint trÃªn `title`
3. **Error handling**: Skip bÃ i lá»—i vÃ  tiáº¿p tá»¥c
4. **Encoding**: Há»— trá»£ gzip, brotli compression
