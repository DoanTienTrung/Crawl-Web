# News Scraper - Scheduler Implementation Plan

## ğŸ“‹ Tá»•ng quan

TÃ i liá»‡u nÃ y mÃ´ táº£ chi tiáº¿t káº¿ hoáº¡ch implement há»‡ thá»‘ng scheduler tá»± Ä‘á»™ng cho news-scraper project.

**YÃªu cáº§u:**
- Táº§n suáº¥t: Má»—i giá»
- MÃ´i trÆ°á»ng: Windows local
- Sources: Táº¥t cáº£ 5 nguá»“n (CafeF, VnExpress, VnEconomy, VOV, Vietnamnet)

## ğŸ¯ Má»¥c tiÃªu

1. Tá»± Ä‘á»™ng cháº¡y scraper má»—i giá» Ä‘á»ƒ thu tháº­p tin tá»©c má»›i
2. Logging chi tiáº¿t Ä‘á»ƒ theo dÃµi quÃ¡ trÃ¬nh
3. Error handling vÃ  recovery
4. Dá»… dÃ ng config vÃ  Ä‘iá»u chá»‰nh lá»‹ch trÃ¬nh
5. Graceful shutdown khi dá»«ng service

## ğŸ—ï¸ Kiáº¿n trÃºc

```
news-scraper/
â”œâ”€â”€ scheduler.py           # ğŸ†• Main scheduler file
â”œâ”€â”€ config.py              # âœï¸ ThÃªm scheduler config
â”œâ”€â”€ requirements.txt       # âœï¸ ThÃªm APScheduler
â”œâ”€â”€ logs/                  # ğŸ†• Folder chá»©a logs
â”‚   â””â”€â”€ scheduler.log      # ğŸ†• Log file
â”œâ”€â”€ .env                   # âœï¸ ThÃªm scheduler settings
â””â”€â”€ README.md              # âœï¸ Cáº­p nháº­t hÆ°á»›ng dáº«n
```

## ğŸ“¦ ThÆ° viá»‡n sá»­ dá»¥ng

### APScheduler v3.10.4
- **LÃ½ do chá»n:**
  - Pure Python, khÃ´ng cáº§n service bÃªn ngoÃ i
  - Há»— trá»£ nhiá»u loáº¡i lá»‹ch trÃ¬nh (interval, cron, date)
  - Persistent jobs (lÆ°u jobs khi restart)
  - Thread-safe, process-safe
  - TÃ­ch há»£p tá»‘t vá»›i Python logging

- **Alternatives Ä‘Ã£ xem xÃ©t:**
  - âŒ Windows Task Scheduler: KhÃ³ config tá»« code
  - âŒ Celery: QuÃ¡ phá»©c táº¡p cho use case nÃ y, cáº§n Redis/RabbitMQ
  - âŒ Cron: KhÃ´ng cÃ³ sáºµn trÃªn Windows

## ğŸ“ Chi tiáº¿t Implementation

### 1. File: `scheduler.py` (Má»šI)

**Chá»©c nÄƒng chÃ­nh:**

```python
# Cáº¥u trÃºc tá»•ng quan
class NewsScraperScheduler:
    def __init__(self):
        - Khá»Ÿi táº¡o APScheduler vá»›i BackgroundScheduler
        - Setup logging
        - Load config tá»« .env

    def setup_jobs(self):
        - ThÃªm job cháº¡y má»—i giá»
        - CÃ³ thá»ƒ config interval tá»« .env

    def run_scraping_job(self):
        - Wrap hÃ m scrape_all() tá»« main.py
        - Try-catch Ä‘á»ƒ handle errors
        - Log káº¿t quáº£ (success/fail, sá»‘ bÃ i crawl Ä‘Æ°á»£c)

    def start(self):
        - Start scheduler
        - Cháº¡y ngay 1 láº§n khi khá»Ÿi Ä‘á»™ng (optional)
        - Graceful shutdown handler (Ctrl+C)

    def stop(self):
        - Shutdown scheduler safely
```

**TÃ­nh nÄƒng:**

1. **Logging nÃ¢ng cao:**
   ```
   [2025-12-29 10:00:00] INFO - Starting scheduled scraping job...
   [2025-12-29 10:00:05] INFO - Scraping CafeF: 45 articles collected
   [2025-12-29 10:01:30] INFO - Scraping VnExpress: 32 articles collected
   [2025-12-29 10:15:22] INFO - âœ“ Job completed: 150 total articles
   [2025-12-29 10:15:22] INFO - Next run: 2025-12-29 11:00:00
   ```

2. **Error handling:**
   - Náº¿u 1 source fail â†’ skip, tiáº¿p tá»¥c sources khÃ¡c
   - Náº¿u database fail â†’ fallback to CSV export only
   - Retry mechanism (optional)

3. **Monitoring:**
   - Log file rotation (max 10MB, keep 5 files)
   - Console output cho debugging
   - Job execution statistics

4. **Graceful shutdown:**
   - Catch Ctrl+C signal
   - Äá»£i job hiá»‡n táº¡i hoÃ n thÃ nh
   - Cleanup resources

### 2. File: `config.py` (Cáº¬P NHáº¬T)

**ThÃªm config cho scheduler:**

```python
class Config:
    # ... existing configs ...

    # Scheduler settings
    SCHEDULER_ENABLED = os.getenv("SCHEDULER_ENABLED", "true").lower() == "true"
    SCHEDULER_INTERVAL_HOURS = int(os.getenv("SCHEDULER_INTERVAL_HOURS", "1"))
    SCHEDULER_RUN_ON_STARTUP = os.getenv("SCHEDULER_RUN_ON_STARTUP", "false").lower() == "true"

    # Logging
    LOG_LEVEL = os.getenv("LOG_LEVEL", "INFO")
    LOG_FILE = os.getenv("LOG_FILE", "logs/scheduler.log")
```

### 3. File: `requirements.txt` (Cáº¬P NHáº¬T)

**ThÃªm dependencies:**

```
APScheduler==3.10.4
```

### 4. File: `.env` (Cáº¬P NHáº¬T)

**ThÃªm settings:**

```bash
# Scheduler Settings
SCHEDULER_ENABLED=true
SCHEDULER_INTERVAL_HOURS=1
SCHEDULER_RUN_ON_STARTUP=false  # true = cháº¡y ngay khi start scheduler

# Logging
LOG_LEVEL=INFO
LOG_FILE=logs/scheduler.log
```

### 5. File: `README.md` (Cáº¬P NHáº¬T)

**ThÃªm section:**

- HÆ°á»›ng dáº«n sá»­ dá»¥ng scheduler
- CÃ¡ch config lá»‹ch trÃ¬nh
- Troubleshooting common issues

## ğŸš€ Usage Flow

### CÃ¡ch sá»­ dá»¥ng:

1. **Cháº¡y scraper thá»§ cÃ´ng (nhÆ° hiá»‡n táº¡i):**
   ```bash
   python main.py
   ```

2. **Cháº¡y scheduler tá»± Ä‘á»™ng:**
   ```bash
   python scheduler.py
   ```

3. **Cháº¡y scheduler nhÆ° Windows Service (nÃ¢ng cao):**
   - Sá»­ dá»¥ng `NSSM` (Non-Sucking Service Manager)
   - Hoáº·c `Task Scheduler` Ä‘á»ƒ cháº¡y khi Windows khá»Ÿi Ä‘á»™ng

### Lá»‹ch trÃ¬nh máº·c Ä‘á»‹nh:

- **Má»—i giá»:** 00:00, 01:00, 02:00, ..., 23:00
- **TÃ¹y chá»‰nh:** Thay Ä‘á»•i `SCHEDULER_INTERVAL_HOURS` trong `.env`

## ğŸ“Š Logging Strategy

### Log levels:

- **INFO:** Normal operations (job started, completed, articles count)
- **WARNING:** Recoverable errors (1 source failed, fallback to CSV)
- **ERROR:** Serious errors (database connection failed, all sources failed)
- **DEBUG:** Detailed info cho troubleshooting (chá»‰ dÃ¹ng khi cáº§n)

### Log rotation:

- Max file size: 10MB
- Keep last 5 files
- Format: `scheduler.log`, `scheduler.log.1`, `scheduler.log.2`, ...

## ğŸ›¡ï¸ Error Handling Strategy

### Level 1: Source-level errors
```python
try:
    articles = scrape_cafef()
except Exception as e:
    logger.warning(f"CafeF scraping failed: {e}")
    # Continue vá»›i sources khÃ¡c
```

### Level 2: Database errors
```python
try:
    db.insert_news(articles)
except Exception as e:
    logger.error(f"Database insert failed: {e}")
    # Fallback to CSV export
    export_to_csv(articles)
```

### Level 3: Scheduler errors
```python
try:
    scheduler.start()
except KeyboardInterrupt:
    logger.info("Scheduler stopped by user")
    scheduler.shutdown()
except Exception as e:
    logger.error(f"Scheduler crashed: {e}")
    # Email notification (optional)
```

## ğŸ”„ Job Execution Flow

```
[Scheduler starts]
    â†“
[Wait until next scheduled time]
    â†“
[10:00:00] Job triggered
    â†“
[10:00:01] Log: "Starting scraping job..."
    â†“
[10:00:05] Scrape CafeF â†’ 45 articles
    â†“
[10:02:10] Scrape VnExpress â†’ 32 articles
    â†“
[10:04:30] Scrape VnEconomy â†’ 28 articles
    â†“
[10:07:15] Scrape VOV â†’ 25 articles
    â†“
[10:10:50] Scrape Vietnamnet â†’ 20 articles
    â†“
[10:11:00] Save to database (150 articles)
    â†“
[10:11:05] Export to CSV
    â†“
[10:11:10] Log: "âœ“ Job completed: 150 articles"
    â†“
[10:11:10] Log: "Next run: 11:00:00"
    â†“
[Wait until 11:00:00]
```

## ğŸ“ˆ Advanced Features (Optional - CÃ³ thá»ƒ thÃªm sau)

### 1. Email notifications
- Gá»­i email khi job fail
- Daily summary report

### 2. Web dashboard
- Flask web UI Ä‘á»ƒ xem job status
- Real-time logs
- Manual trigger button

### 3. Persistent job store
- LÆ°u job state vÃ o SQLite
- Recovery sau khi restart

### 4. Multiple schedules
- Má»™t sá»‘ sources cháº¡y frequent hÆ¡n
- VD: CafeF má»—i 30 phÃºt, sources khÃ¡c má»—i 2 giá»

### 5. Webhook integration
- POST káº¿t quáº£ Ä‘áº¿n API endpoint
- Integration vá»›i Telegram bot

## ğŸ§ª Testing Plan

### 1. Unit tests
- Test scheduler initialization
- Test job execution
- Test error handling

### 2. Integration tests
- Test vá»›i database connection
- Test CSV export fallback

### 3. Manual tests
- Cháº¡y scheduler 24h liÃªn tá»¥c
- Test graceful shutdown
- Test recovery sau crash

## ğŸ“‹ Implementation Checklist

### Phase 1: Core functionality
- [ ] Táº¡o `scheduler.py` vá»›i APScheduler
- [ ] Setup logging system
- [ ] Implement job execution logic
- [ ] Error handling vÃ  recovery
- [ ] Graceful shutdown

### Phase 2: Configuration
- [ ] Update `config.py` vá»›i scheduler settings
- [ ] Update `.env.example` vá»›i scheduler vars
- [ ] Update `requirements.txt`

### Phase 3: Documentation
- [ ] Update `README.md` vá»›i scheduler usage
- [ ] ThÃªm troubleshooting guide
- [ ] Táº¡o `SCHEDULER.md` (chi tiáº¿t hÆ¡n)

### Phase 4: Testing
- [ ] Test manual execution
- [ ] Test scheduled execution
- [ ] Test error scenarios
- [ ] Test log rotation

### Phase 5: Deployment
- [ ] HÆ°á»›ng dáº«n cháº¡y nhÆ° Windows Service
- [ ] Auto-start on Windows boot (optional)

## ğŸ¯ Success Criteria

1. âœ… Scheduler cháº¡y á»•n Ä‘á»‹nh 24/7
2. âœ… Scrape data má»—i giá» thÃ nh cÃ´ng
3. âœ… Error recovery tá»± Ä‘á»™ng
4. âœ… Logs Ä‘áº§y Ä‘á»§, dá»… debug
5. âœ… Resource usage há»£p lÃ½ (<100MB RAM)
6. âœ… KhÃ´ng miss scheduled runs

## âš ï¸ Potential Issues & Solutions

### Issue 1: Memory leak sau nhiá»u giá» cháº¡y
**Solution:**
- Cleanup session objects sau má»—i job
- Monitor memory usage trong logs

### Issue 2: Network timeout
**Solution:**
- TÄƒng timeout trong config
- Retry mechanism vá»›i exponential backoff

### Issue 3: Database connection pool exhausted
**Solution:**
- Close connections properly
- Use connection pooling

### Issue 4: Disk space Ä‘áº§y (do logs)
**Solution:**
- Log rotation
- Compress old logs
- Auto cleanup logs > 30 days

## ğŸ“ Support & Maintenance

### Monitoring checklist:
- [ ] Check logs daily cho errors
- [ ] Monitor disk space (logs folder)
- [ ] Check database size growth
- [ ] Verify data quality (duplicate check)

### Regular maintenance:
- [ ] Weekly: Review error logs
- [ ] Monthly: Clean old CSV exports
- [ ] Monthly: Vacuum database

---

## ğŸš¦ Next Steps

**Náº¿u báº¡n approve plan nÃ y, tÃ´i sáº½:**

1. Táº¡o `scheduler.py` vá»›i Ä‘áº§y Ä‘á»§ tÃ­nh nÄƒng
2. Update `config.py`, `requirements.txt`
3. Táº¡o folder `logs/`
4. Update `README.md` vá»›i hÆ°á»›ng dáº«n
5. Test thá»­ cháº¡y 1 vÃ²ng Ä‘á»ƒ verify

**Timeline Æ°á»›c tÃ­nh:**
- Implementation: ~30 phÃºt
- Testing: ~15 phÃºt
- Documentation: ~10 phÃºt

**Báº¡n cÃ³ muá»‘n Ä‘iá»u chá»‰nh gÃ¬ trong plan nÃ y khÃ´ng?**
